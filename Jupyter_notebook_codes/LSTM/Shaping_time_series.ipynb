{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as s\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_downsample(dsr,samples,csv):\n",
    "    \n",
    "    df = pd.read_csv(csv,usecols=(2,2))\n",
    "    df =df.applymap(lambda s: np.complex(s.replace('i', 'j')))\n",
    "    length =  df.shape[0]\n",
    "    \n",
    "    temp = np.zeros((30000,1),dtype=complex)\n",
    "    temp[:length] = df[:samples]\n",
    "    \n",
    "    \n",
    "    df = df[:samples]\n",
    "    down_sampled = np.zeros((dsr,int(samples/dsr)),dtype=complex)\n",
    "    \n",
    "    for row in range(0,dsr):\n",
    "        down_sampled[row,:]= np.transpose(temp[row::dsr])\n",
    "    print('doone')\n",
    "    \n",
    "    return down_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doone\n",
      "[[-21. +7.j  -9.+20.j -22.+12.j ...   2.-24.j  20. -9.j   0. +0.j]\n",
      " [ 21. +2.j   4.-24.j -23. +1.j ...  23. +1.j  10.+21.j   0. +0.j]\n",
      " [  5.+23.j -25. -1.j -24. -5.j ... -20. -6.j  -4.+25.j   0. +0.j]\n",
      " ...\n",
      " [-25. +6.j  24. -5.j  24. -7.j ...  21. +0.j   0. +0.j   0. +0.j]\n",
      " [ 10.-23.j -25. +2.j   3.-22.j ...  -1.-25.j   0. +0.j   0. +0.j]\n",
      " [-24. +1.j  19.+16.j  -2.+25.j ... -11.+20.j   0. +0.j   0. +0.j]]\n"
     ]
    }
   ],
   "source": [
    "def create_downsample(dsr,samples,csv):\n",
    "    \n",
    "    df = pd.read_csv(csv,usecols=(2,2))\n",
    "    df =df.applymap(lambda s: np.complex(s.replace('i', 'j')))\n",
    "    \n",
    "    #print(df.shape)\n",
    "    length =  df.shape[0]\n",
    "    #print(length)\n",
    "    \n",
    "    temp = np.zeros((30000,1),dtype=complex)\n",
    "    \n",
    "    temp[:length] = df[:samples]\n",
    "    down_sampled = np.zeros((dsr,int(samples/dsr)),dtype=complex)\n",
    "    \n",
    "    for row in range(0,dsr):\n",
    "        down_sampled[row,:]= np.transpose(temp[row::dsr])\n",
    "    print('doone')\n",
    "    \n",
    "    return down_sampled\n",
    "\n",
    "\n",
    "dsr= 10\n",
    "samples = 30000\n",
    "csv = 'act/csi_walk_a2_1.csv'\n",
    "down_sampled = create_downsample(dsr,samples,csv)\n",
    "print(down_sampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(arr,row, size, overlap_per):\n",
    "    start = int(0)\n",
    "    stop = int(start+size)\n",
    "    #print('stop is',stop)\n",
    "    \n",
    "    list = []\n",
    "    temp = np.array(arr[row][:],dtype=complex)\n",
    "    #print(temp)\n",
    "    #print(temp.size)\n",
    "\n",
    "    \n",
    "    while(stop <= temp.size):\n",
    "        datapoint = np.array(temp[start:stop][:],dtype=complex)\n",
    "        #print(datapoint)\n",
    "        list.append(datapoint)\n",
    "        start =int( start+((100-overlap_per)*0.01*size))\n",
    "        stop = int(start  +size)\n",
    "    return list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps = ['t_1', 't_2', 't_3', 't_4', 't_5', 't_6', 't_7', 't_8', 't_9', 't_10', 't_11', 't_12', 't_13', 't_14', 't_15', 't_16', 't_17', 't_18', 't_19', 't_20', 't_21', 't_22', 't_23', 't_24', 't_25', 't_26', 't_27', 't_28', 't_29', 't_30', 't_31', 't_32', 't_33', 't_34', 't_35', 't_36', 't_37', 't_38', 't_39', 't_40', 't_41', 't_42', 't_43', 't_44', 't_45', 't_46', 't_47', 't_48', 't_49', 't_50', 't_51', 't_52', 't_53', 't_54', 't_55', 't_56', 't_57', 't_58', 't_59', 't_60', 't_61', 't_62', 't_63', 't_64', 't_65', 't_66', 't_67', 't_68', 't_69', 't_70', 't_71', 't_72', 't_73', 't_74', 't_75', 't_76', 't_77', 't_78', 't_79', 't_80', 't_81', 't_82', 't_83', 't_84', 't_85', 't_86', 't_87', 't_88', 't_89', 't_90', 't_91', 't_92', 't_93', 't_94', 't_95', 't_96', 't_97', 't_98', 't_99', 't_100', 't_101', 't_102', 't_103', 't_104', 't_105', 't_106', 't_107', 't_108', 't_109', 't_110', 't_111', 't_112', 't_113', 't_114', 't_115', 't_116', 't_117', 't_118', 't_119', 't_120', 't_121', 't_122', 't_123', 't_124', 't_125', 't_126', 't_127', 't_128', 't_129', 't_130', 't_131', 't_132', 't_133', 't_134', 't_135', 't_136', 't_137', 't_138', 't_139', 't_140', 't_141', 't_142', 't_143', 't_144', 't_145', 't_146', 't_147', 't_148', 't_149', 't_150', 't_151', 't_152', 't_153', 't_154', 't_155', 't_156', 't_157', 't_158', 't_159', 't_160', 't_161', 't_162', 't_163', 't_164', 't_165', 't_166', 't_167', 't_168', 't_169', 't_170', 't_171', 't_172', 't_173', 't_174', 't_175', 't_176', 't_177', 't_178', 't_179', 't_180', 't_181', 't_182', 't_183', 't_184', 't_185', 't_186', 't_187', 't_188', 't_189', 't_190', 't_191', 't_192', 't_193', 't_194', 't_195', 't_196', 't_197', 't_198', 't_199', 't_200', 't_201', 't_202', 't_203', 't_204', 't_205', 't_206', 't_207', 't_208', 't_209', 't_210', 't_211', 't_212', 't_213', 't_214', 't_215', 't_216', 't_217', 't_218', 't_219', 't_220', 't_221', 't_222', 't_223', 't_224', 't_225', 't_226', 't_227', 't_228', 't_229', 't_230', 't_231', 't_232', 't_233', 't_234', 't_235', 't_236', 't_237', 't_238', 't_239', 't_240', 't_241', 't_242', 't_243', 't_244', 't_245', 't_246', 't_247', 't_248', 't_249', 't_250', 't_251', 't_252', 't_253', 't_254', 't_255', 't_256', 't_257', 't_258', 't_259', 't_260', 't_261', 't_262', 't_263', 't_264', 't_265', 't_266', 't_267', 't_268', 't_269', 't_270', 't_271', 't_272', 't_273', 't_274', 't_275', 't_276', 't_277', 't_278', 't_279', 't_280', 't_281', 't_282', 't_283', 't_284', 't_285', 't_286', 't_287', 't_288', 't_289', 't_290', 't_291', 't_292', 't_293', 't_294', 't_295', 't_296', 't_297', 't_298', 't_299', 't_300']\n",
    "\n",
    "def create_son(list,target,res,row):\n",
    "    son = pd.DataFrame()  \n",
    "    Y = [target]*(np.shape(list)[0])\n",
    "    Y = pd.DataFrame(Y)\n",
    "    \n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    for i in range(19):\n",
    "        label = str('%s(%d,%d)'%(res,row,i+1))\n",
    "        labels.append(label)\n",
    "    \n",
    "    df_temp = pd.DataFrame(list)\n",
    "    son = son.append(df_temp)\n",
    "\n",
    "    son.columns = time_stamps\n",
    "    son['Y'] = Y\n",
    "    #my_df['file'] = labels\n",
    "    son.insert(0, \"File\", labels, True) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(son.head())\n",
    "\n",
    "    #my_df.to_csv('LSTM_data.csv')\n",
    "    \n",
    "    return son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t_1', 't_2', 't_3', 't_4', 't_5', 't_6', 't_7', 't_8', 't_9', 't_10', 't_11', 't_12', 't_13', 't_14', 't_15', 't_16', 't_17', 't_18', 't_19', 't_20', 't_21', 't_22', 't_23', 't_24', 't_25', 't_26', 't_27', 't_28', 't_29', 't_30', 't_31', 't_32', 't_33', 't_34', 't_35', 't_36', 't_37', 't_38', 't_39', 't_40', 't_41', 't_42', 't_43', 't_44', 't_45', 't_46', 't_47', 't_48', 't_49', 't_50', 't_51', 't_52', 't_53', 't_54', 't_55', 't_56', 't_57', 't_58', 't_59', 't_60', 't_61', 't_62', 't_63', 't_64', 't_65', 't_66', 't_67', 't_68', 't_69', 't_70', 't_71', 't_72', 't_73', 't_74', 't_75', 't_76', 't_77', 't_78', 't_79', 't_80', 't_81', 't_82', 't_83', 't_84', 't_85', 't_86', 't_87', 't_88', 't_89', 't_90', 't_91', 't_92', 't_93', 't_94', 't_95', 't_96', 't_97', 't_98', 't_99', 't_100', 't_101', 't_102', 't_103', 't_104', 't_105', 't_106', 't_107', 't_108', 't_109', 't_110', 't_111', 't_112', 't_113', 't_114', 't_115', 't_116', 't_117', 't_118', 't_119', 't_120', 't_121', 't_122', 't_123', 't_124', 't_125', 't_126', 't_127', 't_128', 't_129', 't_130', 't_131', 't_132', 't_133', 't_134', 't_135', 't_136', 't_137', 't_138', 't_139', 't_140', 't_141', 't_142', 't_143', 't_144', 't_145', 't_146', 't_147', 't_148', 't_149', 't_150', 't_151', 't_152', 't_153', 't_154', 't_155', 't_156', 't_157', 't_158', 't_159', 't_160', 't_161', 't_162', 't_163', 't_164', 't_165', 't_166', 't_167', 't_168', 't_169', 't_170', 't_171', 't_172', 't_173', 't_174', 't_175', 't_176', 't_177', 't_178', 't_179', 't_180', 't_181', 't_182', 't_183', 't_184', 't_185', 't_186', 't_187', 't_188', 't_189', 't_190', 't_191', 't_192', 't_193', 't_194', 't_195', 't_196', 't_197', 't_198', 't_199', 't_200', 't_201', 't_202', 't_203', 't_204', 't_205', 't_206', 't_207', 't_208', 't_209', 't_210', 't_211', 't_212', 't_213', 't_214', 't_215', 't_216', 't_217', 't_218', 't_219', 't_220', 't_221', 't_222', 't_223', 't_224', 't_225', 't_226', 't_227', 't_228', 't_229', 't_230', 't_231', 't_232', 't_233', 't_234', 't_235', 't_236', 't_237', 't_238', 't_239', 't_240', 't_241', 't_242', 't_243', 't_244', 't_245', 't_246', 't_247', 't_248', 't_249', 't_250', 't_251', 't_252', 't_253', 't_254', 't_255', 't_256', 't_257', 't_258', 't_259', 't_260', 't_261', 't_262', 't_263', 't_264', 't_265', 't_266', 't_267', 't_268', 't_269', 't_270', 't_271', 't_272', 't_273', 't_274', 't_275', 't_276', 't_277', 't_278', 't_279', 't_280', 't_281', 't_282', 't_283', 't_284', 't_285', 't_286', 't_287', 't_288', 't_289', 't_290', 't_291', 't_292', 't_293', 't_294', 't_295', 't_296', 't_297', 't_298', 't_299', 't_300']\n"
     ]
    }
   ],
   "source": [
    "name = []\n",
    "size = 300\n",
    "for i in range(size):\n",
    "    label = str('t_%d'%(i+1))\n",
    "    name.append(label)\n",
    "    #name.append(str(','))\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Dad(csv,target):\n",
    "    # This function returns a df of the dad i.e everything consists of one csv file.\n",
    "    title = csv\n",
    "    if(target == 0):\n",
    "        \n",
    "        sstring1 = '/home/surya/Desktop/LSTM/no_act/csi_noactivity'\n",
    "        res = title.replace(sstring1, 'no_act') \n",
    "    else:\n",
    "        sstring1 = '/home/surya/Desktop/LSTM/act/csi_walk_'\n",
    "        res = title.replace(sstring1, '') \n",
    "    sstring2 = '.csv'\n",
    "    \n",
    "    res = res.replace(sstring2, '') \n",
    "    \n",
    "    print(\"WORKING ON %s\"%(res))\n",
    "    \n",
    "    down_sampled= create_downsample(10,30000,csv)\n",
    "    Dad = pd.DataFrame()\n",
    "    for i in range(0,10):\n",
    "        lov = build_data(down_sampled,i,300,50)\n",
    "        son = create_son(lov,target,res,i)\n",
    "        Dad = Dad.append(son)\n",
    "    \n",
    "    return Dad\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under Progress csi_walk_d6e5_2.csv\n",
      "WORKING ON d6e5_2\n",
      "doone\n",
      "Under Progress csi_walk_a4c6_1.csv\n",
      "WORKING ON a4c6_1\n",
      "doone\n",
      "Under Progress csi_walk_c1_1.csv\n",
      "WORKING ON c1_1\n",
      "doone\n",
      "Under Progress csi_walk_a3d6_2.csv\n",
      "WORKING ON a3d6_2\n",
      "doone\n",
      "Under Progress csi_walk_b1_1.csv\n",
      "WORKING ON b1_1\n",
      "doone\n",
      "Under Progress csi_walk_b2_1.csv\n",
      "WORKING ON b2_1\n",
      "doone\n",
      "Under Progress csi_walk_b6e3_2.csv\n",
      "WORKING ON b6e3_2\n",
      "doone\n",
      "Under Progress csi_walk_a4c6_2.csv\n",
      "WORKING ON a4c6_2\n",
      "doone\n",
      "Under Progress csi_walk_e2_1.csv\n",
      "WORKING ON e2_1\n",
      "doone\n",
      "Under Progress csi_walk_b1e4_2.csv\n",
      "WORKING ON b1e4_2\n",
      "doone\n",
      "Under Progress csi_walk_a4_1.csv\n",
      "WORKING ON a4_1\n",
      "doone\n",
      "Under Progress csi_walk_a5e1_2.csv\n",
      "WORKING ON a5e1_2\n",
      "doone\n",
      "Under Progress csi_walk_a6e2_1.csv\n",
      "WORKING ON a6e2_1\n",
      "doone\n",
      "Under Progress csi_walk_e1_1.csv\n",
      "WORKING ON e1_1\n",
      "doone\n",
      "Under Progress csi_walk_a5_1.csv\n",
      "WORKING ON a5_1\n",
      "doone\n",
      "Under Progress csi_walk_a2b1_1.csv\n",
      "WORKING ON a2b1_1\n",
      "doone\n",
      "Under Progress csi_walk_d1e2_1.csv\n",
      "WORKING ON d1e2_1\n",
      "doone\n",
      "Under Progress csi_walk_b6_1.csv\n",
      "WORKING ON b6_1\n",
      "doone\n",
      "Under Progress csi_walk_a3c1_1.csv\n",
      "WORKING ON a3c1_1\n",
      "doone\n",
      "Under Progress csi_walk_a5b6_1.csv\n",
      "WORKING ON a5b6_1\n",
      "doone\n",
      "Under Progress csi_walk_a4d1_2.csv\n",
      "WORKING ON a4d1_2\n",
      "doone\n",
      "Under Progress csi_walk_a2_1.csv\n",
      "WORKING ON a2_1\n",
      "doone\n",
      "Under Progress csi_walk_a2b1_2.csv\n",
      "WORKING ON a2b1_2\n",
      "doone\n",
      "Under Progress csi_walk_d4_1.csv\n",
      "WORKING ON d4_1\n",
      "doone\n",
      "Under Progress csi_walk_c4_1.csv\n",
      "WORKING ON c4_1\n",
      "doone\n",
      "Under Progress csi_walk_a4d1_1.csv\n",
      "WORKING ON a4d1_1\n",
      "doone\n",
      "Under Progress csi_walk_d3_1.csv\n",
      "WORKING ON d3_1\n",
      "doone\n",
      "Under Progress csi_walk_a5b6_2.csv\n",
      "WORKING ON a5b6_2\n",
      "doone\n",
      "Under Progress csi_walk_a3c1_2.csv\n",
      "WORKING ON a3c1_2\n",
      "doone\n",
      "Under Progress csi_walk_c6e4_2.csv\n",
      "WORKING ON c6e4_2\n",
      "doone\n",
      "Under Progress csi_walk_c6_1.csv\n",
      "WORKING ON c6_1\n",
      "doone\n",
      "Under Progress csi_walk_d6e5_1.csv\n",
      "WORKING ON d6e5_1\n",
      "doone\n",
      "Under Progress csi_walk_a3_1.csv\n",
      "WORKING ON a3_1\n",
      "doone\n",
      "Under Progress csi_walk_a3d6_1.csv\n",
      "WORKING ON a3d6_1\n",
      "doone\n",
      "Under Progress csi_walk_d2_1.csv\n",
      "WORKING ON d2_1\n",
      "doone\n",
      "Under Progress csi_walk_c6e4_1.csv\n",
      "WORKING ON c6e4_1\n",
      "doone\n",
      "Under Progress csi_walk_c1e3_1.csv\n",
      "WORKING ON c1e3_1\n",
      "doone\n",
      "Under Progress csi_walk_e5_1.csv\n",
      "WORKING ON e5_1\n",
      "doone\n",
      "Under Progress csi_walk_c3_1.csv\n",
      "WORKING ON c3_1\n",
      "doone\n",
      "Under Progress csi_walk_e4_1.csv\n",
      "WORKING ON e4_1\n",
      "doone\n",
      "Under Progress csi_walk_a2e6_2.csv\n",
      "WORKING ON a2e6_2\n",
      "doone\n",
      "Under Progress csi_walk_c5_1.csv\n",
      "WORKING ON c5_1\n",
      "doone\n",
      "Under Progress csi_walk_b1e4_1.csv\n",
      "WORKING ON b1e4_1\n",
      "doone\n",
      "Under Progress csi_walk_c1e3_2.csv\n",
      "WORKING ON c1e3_2\n",
      "doone\n",
      "Under Progress csi_walk_b6e3_1.csv\n",
      "WORKING ON b6e3_1\n",
      "doone\n",
      "Under Progress csi_walk_a6e2_2.csv\n",
      "WORKING ON a6e2_2\n",
      "doone\n",
      "Under Progress csi_walk_a1e5_2.csv\n",
      "WORKING ON a1e5_2\n",
      "doone\n",
      "Under Progress csi_walk_a2e6_1.csv\n",
      "WORKING ON a2e6_1\n",
      "doone\n",
      "Under Progress csi_walk_e3_1.csv\n",
      "WORKING ON e3_1\n",
      "doone\n",
      "Under Progress csi_walk_a1e5_1.csv\n",
      "WORKING ON a1e5_1\n",
      "doone\n",
      "Under Progress csi_walk_b4_1.csv\n",
      "WORKING ON b4_1\n",
      "doone\n",
      "Under Progress csi_walk_a5e1_1.csv\n",
      "WORKING ON a5e1_1\n",
      "doone\n",
      "Under Progress csi_walk_b5_1.csv\n",
      "WORKING ON b5_1\n",
      "doone\n",
      "Under Progress csi_walk_b3_1.csv\n",
      "WORKING ON b3_1\n",
      "doone\n",
      "Under Progress csi_walk_a6_1.csv\n",
      "WORKING ON a6_1\n",
      "doone\n",
      "Under Progress csi_walk_b1e2_2.csv\n",
      "WORKING ON b1e2_2\n",
      "doone\n",
      "Under Progress csi_walk_d6_1.csv\n",
      "WORKING ON d6_1\n",
      "doone\n",
      "Under Progress csi_walk_c2_1.csv\n",
      "WORKING ON c2_1\n",
      "doone\n",
      "Under Progress csi_walk_d5_1.csv\n",
      "WORKING ON d5_1\n",
      "doone\n",
      "Under Progress csi_walk_d1_1.csv\n",
      "WORKING ON d1_1\n",
      "doone\n",
      "MISSION ACCOMPLISED\n"
     ]
    }
   ],
   "source": [
    "directory = '/home/surya/Desktop/LSTM/act'\n",
    "z = '/home/surya/Desktop/LSTM/act/'\n",
    "\n",
    "def create_godfather(directory,target):\n",
    "    if(target == 0):\n",
    "        GF = pd.DataFrame()\n",
    "    else:\n",
    "        GF = pd.read_csv('LSTM_data.csv')\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            a = z + filename\n",
    "            print('Under Progress',filename)\n",
    "            csv = a\n",
    "            Dad = create_Dad(csv,target)\n",
    "            GF = GF.append(Dad)\n",
    "    return GF\n",
    "            \n",
    "GF = create_godfather(directory,1)\n",
    "GF.to_csv('LSTM_data.csv')\n",
    "\n",
    "print(\"MISSION ACCOMPLISED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        no_act_1(0,1)\n",
      "1        no_act_1(0,2)\n",
      "2        no_act_1(0,3)\n",
      "3        no_act_1(0,4)\n",
      "4        no_act_1(0,5)\n",
      "             ...      \n",
      "11775       d1_1(9,15)\n",
      "11776       d1_1(9,16)\n",
      "11777       d1_1(9,17)\n",
      "11778       d1_1(9,18)\n",
      "11779       d1_1(9,19)\n",
      "Name: File, Length: 11780, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('LSTM_data.csv')\n",
    "\n",
    "for tits in df.columns:\n",
    "    if(tits != 'File'):\n",
    "        \n",
    "        if df[tits].dtypes =='O':\n",
    "            df[tits] = df[tits].str.replace('i','j')\n",
    "            df[tits] = df[tits].str.replace(' ','')\n",
    "            df[tits] = df[tits].apply(lambda x: np.complex(x))\n",
    "print(df[df.columns[]])\n",
    "#print(df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        14.035669\n",
      "1        12.806248\n",
      "2        13.038405\n",
      "3        13.038405\n",
      "4        12.649111\n",
      "           ...    \n",
      "11775    25.553865\n",
      "11776    25.000000\n",
      "11777    26.172505\n",
      "11778    25.059928\n",
      "11779    22.803509\n",
      "Name: t_1, Length: 11780, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(abs(df[df.columns[3]]))\n",
    "df.to_csv('LSTM_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
